{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U accelerate==0.27.1\n!pip install -q -U transformers==4.38.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U datasets==2.16.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport transformers\nimport tensorflow as tf\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import AdamWeightDecay","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:08.919395Z","iopub.execute_input":"2024-03-23T17:15:08.919830Z","iopub.status.idle":"2024-03-23T17:15:16.332345Z","shell.execute_reply.started":"2024-03-23T17:15:08.919788Z","shell.execute_reply":"2024-03-23T17:15:16.331332Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-23 17:15:12.372234: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-23 17:15:12.372300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-23 17:15:12.373761: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = \"Mr-Vicky-01/English-Tamil-Translator\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:16.337944Z","iopub.execute_input":"2024-03-23T17:15:16.338322Z","iopub.status.idle":"2024-03-23T17:15:20.939542Z","shell.execute_reply.started":"2024-03-23T17:15:16.338287Z","shell.execute_reply":"2024-03-23T17:15:20.938464Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# def language_translator(text):\n#     tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n#     model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n#     # model = AutoModelForSeq2SeqLM.from_pretrained(\"finetune-EN-to-Ta/\")\n#     tokenized = tokenizer([text], return_tensors='pt')\n#     out = model.generate(**tokenized, max_length=128)\n#     return tokenizer.decode(out[0],skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:20.941297Z","iopub.execute_input":"2024-03-23T17:15:20.942224Z","iopub.status.idle":"2024-03-23T17:15:20.946880Z","shell.execute_reply.started":"2024-03-23T17:15:20.942183Z","shell.execute_reply":"2024-03-23T17:15:20.945823Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"raw_datasets = load_dataset(\"HariprasathSB/tamil_summarization\")","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:20.949548Z","iopub.execute_input":"2024-03-23T17:15:20.950162Z","iopub.status.idle":"2024-03-23T17:15:24.742791Z","shell.execute_reply.started":"2024-03-23T17:15:20.950133Z","shell.execute_reply":"2024-03-23T17:15:24.741923Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:24.743907Z","iopub.execute_input":"2024-03-23T17:15:24.744211Z","iopub.status.idle":"2024-03-23T17:15:24.751443Z","shell.execute_reply.started":"2024-03-23T17:15:24.744183Z","shell.execute_reply":"2024-03-23T17:15:24.750428Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Summary', 'Text'],\n        num_rows: 116936\n    })\n    test: Dataset({\n        features: ['Summary', 'Text'],\n        num_rows: 31779\n    })\n    val: Dataset({\n        features: ['Summary', 'Text'],\n        num_rows: 25523\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:24.752808Z","iopub.execute_input":"2024-03-23T17:15:24.753093Z","iopub.status.idle":"2024-03-23T17:15:24.763922Z","shell.execute_reply.started":"2024-03-23T17:15:24.753069Z","shell.execute_reply":"2024-03-23T17:15:24.763001Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'Summary': 'முக்கியமான நான்கு நவீன கண்டுபிடிப்புக ளை  தாங்களே செய்ததாக சீனா உரிமை கோரும் நிலையில், அத்தகைய உரிமை கோரல்களையும், அது தொடர்பான உண்மைகளையும் ஒப்பிடும் ஓர் அலசல்  இது .',\n 'Text': 'உரிமை கோருதல்: அதிவேக ரயில், செல்பேசி வழியாக பணம் செலுத்துதல், இ-வணிகம் மற்றும் மிதிவண்டி பகிர்வு ஆகியவற்றை சீனா கண்டுபிடித்தது. உண்மை சோதனை தீர்ப்பு: இந்த தொழில்நுட்பங்களில் எதையும் சீனா கண்டுபிடிக்கவில்லை. இந்த தொழில்நுட்பங்களை மிகப் பெரிய அளவில் நடைமுறைப்படுத்தும் பாதைக்கு சீனா அழைத்து சென்றுள்ளது. அதிவேக ரயில், செல்பேசி வழியாக பணம் செலுத்துதல், இ-வணிகம் மற்றும் மிதிவண்டி பகிர்வு ஆகியவற்றை சீனா கண்டுபிடித்ததாக உரிமை கோரும் தகவல்கள் 2017ம் ஆண்டு மே மாதம் முதல் சீனாவின் அரசு ஊடகங்களில் மீண்டும் மீண்டும் வெளிவந்தன. சீன தேசிய மக்கள் பேரவையின் பிரதிநிதிகளில் ஒருவரும், சீன இணைய ஜாம்பவான் நிறுவனமான \\'டென்சென்று\\' வின் முதன்மை செயலதிகாரியாகவும் அறியப்படும் போனி மாவால், சீனாவின் தேசிய மக்கள் பேரவை கூட்டத்தில் சமீபத்தில் இதனை மீண்டும் தெரிவித்துள்ளார். \\'த ஹூருன் குளோபல்\\' பணக்காரர்கள் பட்டியலின்படி, சீனாவில் இவரொரு பணக்காரரும்கூட. \"அதிவேக ரயில், செல்பேசி வழியாக பணம் செலுத்துதல், இ-வணிகம் மற்றும் மிதிவண்டி பகிர்வு ஆகிய சீனாவில் கண்டுபிடிக்கப்பட்ட தொழில்நுட்பங்களை நாம் பெற்றுள்ளோம்,\" என்று சீன தேசிய மக்கள் பேரவையில் செய்தியாளர்களிடம் அவர் தெரிவித்தார். ஆனால், இந்த தொழில்நுட்பங்கள் சீனாவில் தோன்றவில்லை. அவை எல்லாம் பல தசாப்தங்களுக்கு முன்னரே கண்டுபிடிக்கப்பட்டவை. உரிமை கோருதல் எப்போது தொடங்கியது? 2017ம் ஆண்டு மே மாதம் பெய்ஜிங் ஃபாரின் ஸ்டடீஸ் பல்கலைக்கழகம் நடத்திய ஆய்விலிருந்து இந்த உரிமை கோருதல் தொடங்கியதாக தோன்றுகிறது. 20 நாடுகளிலுள்ள இளைஞர்களிடம் நடத்தப்பட்ட இந்த ஆய்வில், சீனாவில் இருந்து தங்களுடைய நாட்டிற்கு கொண்டு வருவதற்கு அவர்கள் மிகவும் விரும்புகின்ற தொழில்நுட்பங்கள் பற்றி கேட்கப்பட்டது. இதில் பங்கேற்றவர்கள் அதிவேக ரயில், செல்பேசி வழியாக பணம் செலுத்துதல், இ-வணிகம் மற்றும் மிதிவண்டி பகிர்வு ஆகியவற்றை தெரிவித்திருந்தனர். அதுமுதல், நவீன காலத்தில் இந்த தொழில்நுட்பங்கள் சீனாவின் \"நான்கு புதிய மாபெரும் கண்டுபிடிப்புகள்\" என்று சீனாவின் ஊடகங்களும், அதிகாரிகளும் விளம்பரப்படுத்த தொடங்கிவிட்டனர். உரிமை கோருதலை தொடர்ந்து மேற்கொள்வது ஏன்? \"நான்கு புதிய கண்டுபிடிப்புகள்\" என்கிற சொற்றொடர் பழங்கால சீனாவின் தாள், வெடிமருந்து, அச்சு, திசைக்காட்டும் கருவி என்ற \"நான்கு பெரிய கண்டுபிடிப்புக்களை\" நினைவுபடுத்துகிறது. 2020ம் ஆண்டுக்குள் \"புத்தாக்க நாடு\" என்று குறிப்பிடப்படும் நாடாக உருவாக்க தொழில்நுட்ப மேம்பாட்டில் அதிக முக்கியத்துவத்தை சீனா வழங்கி வருகிறது. மேற்குல நாடுகளின் தொழில்நுட்ப ஆதிக்கத்திற்கு பல ஆண்டுகளாக அடிமையாகி இருந்த பின்னர். முக்கிய தொழில்நுட்பங்களை தானே கொண்டிருப்பதன் முக்கியத்துவத்தை சீனா உணர்ந்துள்ளது. இவ்வாறு செய்வதன் மூலமே உண்மையான சுதந்திரத்தை பெற முடியும் என்றும், அப்போதுதான் கூட்டாளி மற்றும் போட்டி நாடுகளிடம் மரியாதையை வென்றெடுக்க முடியும் என்று \\'சின்குவா\\' செய்தி நிறுவனம் தெரிவித்திருக்கிறது. அமெரிக்காவுக்கு அடுத்தபடியாக ஆய்வு மற்றும் மேம்பாட்டுக்கு செய்கின்ற செலவில் சீனா ஏற்கெனவே இரண்டாவதாக உள்ளது. 2015ம் ஆண்டு உலக அளவில் நடத்தப்பட்ட ஆய்வுக்கான 2 லட்சம் கோடி டாலர் மொத்த செலவில் 21 சதவீதத்தை சீனா செலவு செய்துள்ளது என்று உலக பொருளாதார மன்றம் தெரிவிக்கிறது. அதிவேக ரயில் \"அதிவேக ரயில்\" என்பதற்கு தலைசிறந்த வரையறை எதுவும் இல்லை. புதிய தண்டவாளத்தில் மணிக்கு குறைந்தது 250 கிலோமீட்டர் வேகம் செல்லும் ரயிலை \"அதிவேக\" ரயில் என்று ஐரோப்பிய ஒன்றியம் வரையறுக்கிறது. 1964ம் ஆண்டு ஜப்பானின் ஷின்கான்சென் அல்லது புல்லட் ரயில் சேவைதான் முதலாவது அதிவேக ரயில் சேவை என்று அனைத்துலக ரயில் நிறுவனம் (யுஐசி) கூறுகிறது. ஐரோப்பாவில் குறிப்பிடத்தக்க வேகப்பதிவுகள் ஏற்கெனவே பதிவு செய்யப்பட்டுள்ளன. 1955ம் ஆண்டு பிரான்ஸில் ரயில் ஒன்று மணிக்கு 331 கிலோமீட்டர் வேகத்தை எட்டியது. ஆனால், மணிக்கு 210 கிலோமீட்டர் அதிகபட்ச வேகத்தில் டோக்கியோ முதல் ஒசாகாவுக்கு சென்ற ரயில்தான் முதல்முறையாக வேகமான பயணச்சேவை அளித்த ஒன்றாகும். சீனா அதனுடைய முதலாவது அதிவேக ரயில் சேவையை பெய்ஜிங் முதல் தியன்சின் வரை 2008ம் ஆண்டுதான் தொடங்கியது. செல்பேசி வழியாக பணம் செலுத்துதல் செல்பேசி வழியாக பணம் செலுத்தும் சேவை முதல்முறையாக  பின்லாந்தில் 1997ம் ஆண்டு நடைபெற்றது. ஹெல்சிங்கி விமானநிலையத்தில் கோகோ கோலா எந்திரங்கள், இசை ஜூக்பாக்ஸ் மற்றும் பானங்கள் விற்கும் எந்திரங்கள் ஆகியவற்றை தொலைபேசி வழியாக பணம் செலுத்தும் எண்ணை அழைப்பதன் மூலம் பின்லாந்து தொலைபேசி நிறுவனம் செயல்படுத்தியதாக அப்போது வெளியான உள்ளூர் செய்திகள் தெரிவித்தன. இருப்பினும், 2014ம் ஆண்டு ஆப்பிள் பணம் செலுத்தும் வசதி முதலில் தோன்றியபோதுதான், செல்பேசி வழியாக பணம் செலுத்துவது உண்மையில் தொடங்கியது என்றும் சிலர் குறிப்பிடுகின்றனர். இ-வணிகம் 1979ம் ஆண்டு இணையம் வழியாக வணிகம் செய்கின்ற கருத்தியலை கண்டுபிடித்த பெருமையை பெறுகிறார் மைக்கேல் அல்டிரிச் என்கிற ஆங்கிலேயர். வீடியோடெக்ஸ் என்று அழைக்கப்படும் தொழில்நுட்பம் ஒன்றை பயன்படுத்தி அல்டிரிச் சாதாரண தொலைக்காட்சி பெட்டியை ஒரு தொலைபேசி இணைப்பு மூலம் உள்ளூர் சில்லறை வியாபாரியின் கணினியோடு இணைத்தார். ஆனால், அமேசானும், இபேயும் அவற்றின் இணைய தளங்களை 1995ல் தொடக்கிய பிறகே இ-வணிகம் பிரபலமடைந்தது. மிதிவண்டி பகிர்வு இறுதியாக, மிதிவண்டி பகிர்வு பற்றிய முதலாவது கருத்து \"ஒய்ட் மிதிவண்டி திட்டம்\" என்று அழைக்கப்படுகிறது. நெதர்லாந்து எதிர் கலாசார இயக்கமான \\'புரேவோ\\' 1960களில் ஆம்ஸ்டர்டாமில் இந்த திட்டத்தை அறிமுகப்படுத்தியது. திருட்டை ஊக்குவிப்பதாக இருந்த தருணத்தில், மிதிவண்டிகளை காவல்துறையினர் கைப்பற்றினர். மிக பெரிய அளவில் மிதிவண்டி பகிர்வு திட்டம் 1990களில் ஐரோப்பிய நகரங்களில் தொடங்கியது. இதனை முதன்முதலில் அறிமுகப்படுத்திய பெருமையை பெறுகிறது கோபன்ஹெகன் நகரம். \\'மோபைக்\\' மற்றும் \\'ஒஃபோ\\' போன்ற சீன நிறுவனங்களும் \"டாக்லெஸ்\" (நிறுத்தும் இடமற்ற) மிதிவண்டியை பகிர்ந்து கொள்ளும் ஒரு புதிய திட்டத்திற்கு வித்திட்டன. இதன் மூலம் பயனர்கள் எங்கு மிதிவண்டிகள் உள்ளன என்று தங்களுடைய திறன்பேசி மூலம் கண்டறியவும், குறிப்பிட்ட இடத்தில்தான் நிறுத்த வேண்டும் என்றில்லாமல், எங்குவேண்டுமானாலும் நிறுத்தவும் வசதி தோன்றியது. மேலாதிக்க வீரர் இதுபோல, பிற நாடுகளைவிட மிகப் பெரியதாக சீனா நடைமுறைப்படுத்தியுள்ளது. இந்த நான்கு தொழில்நுட்பங்களை பொறுத்தமட்டில் சீனா இதைதான் செய்துள்ளது. \"சீனாவில் மிகப் பெரிய அளவில் பரவலாயிருக்கும் \"புதிய நான்கு பெரிய கண்டுபிடிப்புகளும்\" சீனாவில் தோன்றவில்லை என்று சிலர் வாதிடலாம். அது உண்மையும்கூட. ஆனால், புதிய கண்டுபிடிப்புகளோடு இந்த தொழில்நுட்பங்களை சீனா நடைமுறைப்படுத்தியுள்ளது\" என்கிறார் சியாமென் பல்கலைக்கழகத்தில் பேராசிரியரான சு கொங்செங். உலகிலேயே அதிக நீளமுள்ள அதிவேக ரயில் பாதை தற்போது சீனாவில் உள்ளது. தற்போது உள்ள சுமார் 25 ஆயிரம் கிலோமீட்டர் அதிவேக ரயில் பாதையை 2030ம் ஆண்டுக்குள் இரட்டிப்பாக்கும் தொலைநோக்கு திட்டத்தையும் சீனா கொண்டுள்ளது. 2017ம் ஆண்டின் முதல் 10 மாதங்களில் சீனாவின் செல்பேசி வழியாக செலுத்திய மொத்த தொகை 12.7 டில்லிரியன் டாலராகும். உலகிலேயே செல்பேசி வழியாக செலுத்தப்பட்ட தொகையில் இதுவே அதிக தொகை என்று சீனாவின் தொழில்துறை மற்றும் தகவல் தொழில் நுட்ப அமைச்சகம் தெரிவித்துள்ளது. 2017ம் ஆண்டு \\'பிரைஸ்வாட்டர்ஹெவுஸ் கூப்பர்ஸ்\\' நிறுவனத்தால் நடத்தப்பட்ட ஆய்வில் 700 மில்லியன் இணையதள பயன்பாட்டளரோடு உலகிலேயே மிகப் பெரிய மற்றும் வேகமாக வளரும் இ-வணிக சந்தையாக சீனா உள்ளது. சீனாவில் 400 மில்லியின் பயன்பாட்டாளர்கள் மிதிவண்டி பகிர்வு திட்டத்தில் பதிவு செய்திருப்பதாகவும், 23 மில்லியன் பகிர்வு மிதிவண்டிகள் சீனாவில் உள்ளதாகவும் பிப்ரவரி மாதம் சீனப் போக்குவரத்து அமைச்சகத்தின் துணை அமைச்சர் தெரிவித்திருக்கிறார். பிற செய்திகள் சமூக ஊடகங்களில் பிபிசி தமிழ்:'}"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 128\nprefix = \"summarize: \"\n\ndef preprocess_function(examples):\n    inputs = [prefix + str(ex) for ex in examples['Text']]\n    targets = [str(ex) for ex in examples['Summary']]\n    model_inputs = tokenizer(inputs, max_length=max_input_length,padding=\"max_length\", truncation=True)\n\n    # Setup the tokenizer for targets\n    # with tokenizer.as_target_tokenizer():\n    labels = tokenizer(targets, max_length=max_target_length,padding=\"max_length\",truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:24.765256Z","iopub.execute_input":"2024-03-23T17:15:24.765950Z","iopub.status.idle":"2024-03-23T17:15:24.774002Z","shell.execute_reply.started":"2024-03-23T17:15:24.765914Z","shell.execute_reply":"2024-03-23T17:15:24.773047Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"preprocess_function(raw_datasets[\"train\"][1:2])","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:24.775216Z","iopub.execute_input":"2024-03-23T17:15:24.775680Z","iopub.status.idle":"2024-03-23T17:15:24.789306Z","shell.execute_reply.started":"2024-03-23T17:15:24.775646Z","shell.execute_reply":"2024-03-23T17:15:24.788319Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[128022, 4088, 2516, 5598, 9, 11162, 15238, 5167, 74734, 3756, 3000, 23198, 12037, 11376, 7128, 65169, 7422, 42996, 301, 3000, 15707, 5996, 35019, 5283, 2764, 49239, 3452, 7422, 70100, 17190, 17066, 4840, 5996, 16044, 76616, 35768, 2679, 64942, 5, 4167, 20405, 24588, 3690, 18182, 7931, 3000, 15238, 83532, 13488, 13248, 6823, 5, 4167, 13378, 42586, 11968, 19860, 3690, 5654, 3441, 74642, 10230, 60109, 2895, 3585, 88327, 27116, 5538, 54028, 20405, 110280, 5, 40695, 11030, 19985, 94355, 47406, 17900, 19973, 43338, 24168, 5422, 13496, 85850, 41524, 104334, 6087, 20400, 72969, 2679, 71010, 52088, 20730, 2764, 36276, 19973, 20405, 44088, 20422, 5, 99366, 107470, 60317, 67369, 3452, 5900, 21872, 99366, 91395, 6285, 82334, 12416, 42579, 3263, 7931, 4840, 5538, 71175, 3690, 18182, 7931, 3000, 15238, 9810, 104334, 6087, 20400, 56074, 9110, 3316, 19363, 2124, 5392, 51008, 52863, 5, 42447, 9810, 76616, 35768, 7422, 42996, 47840, 10508, 3585, 6538, 3263, 34166, 41132, 9810, 3690, 5654, 3441, 74642, 21193, 49661, 86274, 23771, 14517, 54723, 6823, 3690, 18182, 7931, 3000, 15238, 5, 61768, 32117, 9, 105374, 27513, 4840, 2748, 44886, 24333, 19509, 16136, 17977, 9, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[128022, 9322, 18182, 13641, 28083, 6321, 31893, 5507, 76616, 35768, 7422, 5040, 16136, 9448, 3690, 18182, 7931, 3000, 15238, 3690, 5654, 7128, 43273, 91395, 104334, 6087, 20400, 56074, 9110, 26818, 15580, 110280, 5, 99366, 26597, 91395, 104334, 72156, 6855, 679, 45594, 3565, 11950, 13460, 41132, 5040, 13248, 21562, 12416, 28940, 3690, 18182, 7931, 3000, 15238, 4, 93351, 2918, 22433, 2764, 42052, 3790, 273, 26597, 265, 104484, 2679, 45594, 3565, 18157, 56105, 15580, 13463, 2679, 44968, 7904, 110280, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test = raw_datasets.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:24.790550Z","iopub.execute_input":"2024-03-23T17:15:24.790866Z","iopub.status.idle":"2024-03-23T17:15:33.054859Z","shell.execute_reply.started":"2024-03-23T17:15:24.790840Z","shell.execute_reply":"2024-03-23T17:15:33.054020Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_test","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:36.541550Z","iopub.execute_input":"2024-03-23T17:15:36.542314Z","iopub.status.idle":"2024-03-23T17:15:36.548286Z","shell.execute_reply.started":"2024-03-23T17:15:36.542281Z","shell.execute_reply":"2024-03-23T17:15:36.547214Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Summary', 'Text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 116936\n    })\n    test: Dataset({\n        features: ['Summary', 'Text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 31779\n    })\n    val: Dataset({\n        features: ['Summary', 'Text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 25523\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel_args = Seq2SeqTrainingArguments(\n    output_dir=\"finetuned-Tamil_summary\",  \n    overwrite_output_dir=True,  \n    do_train=True,  \n    logging_dir=\"logs\",  \n    logging_steps=50,  # Increase logging frequency for more insights\n    save_steps=5000000,  # Save model checkpoints more frequently\n    save_total_limit=1,  # Keep more checkpoints\n    num_train_epochs=1,  # Extend training to allow for more optimization\n    per_device_train_batch_size=2,  # Increase batch size for more efficient training\n    gradient_accumulation_steps=2,  # Increase gradient accumulation for stable training\n    learning_rate=4e-5,  # Slightly lower learning rate to fine-tune more gently\n    warmup_steps=2500,  # Increase warmup steps for better adaptation\n    weight_decay=0.01,  \n    adam_beta1=0.9,  \n    adam_beta2=0.98,  \n    adam_epsilon=1e-8,  \n    lr_scheduler_type=\"linear\",  \n    predict_with_generate=True,  \n    fp16=True,  \n    seed=42,  \n    report_to=\"wandb\",  \n    run_name=\"Tamil_summary\",  \n)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:39.421754Z","iopub.execute_input":"2024-03-23T17:15:39.422148Z","iopub.status.idle":"2024-03-23T17:15:39.489523Z","shell.execute_reply.started":"2024-03-23T17:15:39.422114Z","shell.execute_reply":"2024-03-23T17:15:39.488409Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:40.366226Z","iopub.execute_input":"2024-03-23T17:15:40.366911Z","iopub.status.idle":"2024-03-23T17:15:40.371391Z","shell.execute_reply.started":"2024-03-23T17:15:40.366879Z","shell.execute_reply":"2024-03-23T17:15:40.370292Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    model_args,\n    train_dataset=tokenized_test[\"train\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:42.931903Z","iopub.execute_input":"2024-03-23T17:15:42.932909Z","iopub.status.idle":"2024-03-23T17:15:43.839267Z","shell.execute_reply.started":"2024-03-23T17:15:42.932874Z","shell.execute_reply":"2024-03-23T17:15:43.838466Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T17:15:44.351105Z","iopub.execute_input":"2024-03-23T17:15:44.351858Z","iopub.status.idle":"2024-03-23T18:31:13.773818Z","shell.execute_reply.started":"2024-03-23T17:15:44.351824Z","shell.execute_reply":"2024-03-23T18:31:13.772351Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvickyvijay069\u001b[0m (\u001b[33mvicky12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240323_171550-pat2jugw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vicky12/huggingface/runs/pat2jugw' target=\"_blank\">Tamil_summary</a></strong> to <a href='https://wandb.ai/vicky12/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vicky12/huggingface' target=\"_blank\">https://wandb.ai/vicky12/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vicky12/huggingface/runs/pat2jugw' target=\"_blank\">https://wandb.ai/vicky12/huggingface/runs/pat2jugw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3454' max='29234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3454/29234 1:14:46 < 9:18:26, 0.77 it/s, Epoch 0.12/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>10.722000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>8.061500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>6.054900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>4.870300</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>4.372100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>4.274300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>3.752800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.726800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>3.066500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.048600</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>2.576700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.297500</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.897900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.519900</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.157900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.977100</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.840700</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.831800</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.896000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.799900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.758900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.858600</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.832100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.898300</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.819300</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.844500</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.831500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.794800</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.827200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.780300</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.639000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.765500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.756800</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.897500</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.759400</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.745000</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.668500</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.696000</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.703800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.739800</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.850600</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.678200</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.594400</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.638900</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.739400</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.666900</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.809900</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.778500</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.662100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.744100</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.643200</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.760100</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.647900</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.706000</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.695200</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.711400</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.643700</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.600500</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.610500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.748000</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>0.629300</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.797700</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>0.704300</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.696600</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.584000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.649900</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>0.654100</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.679000</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>0.632500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1966\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"trainer.model.save_pretrained('Tamil-Summarization-model1')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:31:18.021428Z","iopub.execute_input":"2024-03-23T18:31:18.021844Z","iopub.status.idle":"2024-03-23T18:31:21.635972Z","shell.execute_reply.started":"2024-03-23T18:31:18.021809Z","shell.execute_reply":"2024-03-23T18:31:21.634392Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"model1 = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/Tamil-Summarization-model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:36:15.997105Z","iopub.execute_input":"2024-03-23T18:36:15.997773Z","iopub.status.idle":"2024-03-23T18:36:19.158462Z","shell.execute_reply.started":"2024-03-23T18:36:15.997737Z","shell.execute_reply":"2024-03-23T18:36:19.157096Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def generate_answer(text):\n    tokenized = tokenizer([text], return_tensors='pt')\n    out = model1.generate(**tokenized, max_length=128)\n    return tokenizer.decode(out[0],skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:36:19.160639Z","iopub.execute_input":"2024-03-23T18:36:19.161085Z","iopub.status.idle":"2024-03-23T18:36:19.169058Z","shell.execute_reply.started":"2024-03-23T18:36:19.161019Z","shell.execute_reply":"2024-03-23T18:36:19.167890Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# text_to_translate = raw_datasets[\"test\"][\"en\"][5]\noutput = generate_answer(\"he was running faster\")\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:36:20.837031Z","iopub.execute_input":"2024-03-23T18:36:20.837936Z","iopub.status.idle":"2024-03-23T18:36:22.887772Z","shell.execute_reply.started":"2024-03-23T18:36:20.837886Z","shell.execute_reply":"2024-03-23T18:36:22.886436Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"அவர் விரைவாக ஓடி வந்தார்.\n","output_type":"stream"}]},{"cell_type":"code","source":"prefix = \"summarize: \"\noutput = generate_answer(prefix + \"\"\"கோட்பாட்டு மொழியியல் பொதுவாக, ஓரளவுக்குத் தனித்தனியாக ஆராயத்தக்க வகையில் பல்வேறு பிரிவுகளாக வகுக்கப்படுகிறது. கீழ்வரும் பிரிவுகள் இன்று பரவலாக ஏற்றுக்கொள்ளப்படுகின்றன:\n\nஒலிப்பியல் (phonetics), ஒரு மொழியில் பயன்படுத்தப்படும் வெவ்வேறு ஒலிகள் பற்றிய துறை;\nஒலியியல் (phonology), ஒரு மொழியின் அடிப்படை ஒலிகளின் வடிவுரு பற்றி ஆராயும் துறை;\nஉருபனியல், சொற்களின் உள் அமைப்புப் பற்றி ஆராயும் துறை;\nசொற்றொடரியல் (syntax), எவ்வாறு சொற்கள் சேர்ந்து இலக்கணத்துக்குட்பட்ட வசனங்களை உருவாக்குகின்றன என்பதை ஆராயும் துறை;\nசொற்பொருளியல் (semantics), சொற்களின் நேரடியான (literal) பொருளை ஆராய்தலுக்கும்,(சொல் குறிக்கும் பொருள் (lexical semantics)), அவை சேர்ந்து உருவாக்கும் வசனங்களின் நேரடியான பொருள்களையும் ஆராயும் துறை;\nமொழிநடை (stylistics), மொழியின் பாணிகளை ஆராயும் துறை;\nசூழ்பொருளியல் (pragmatics), தொடர்புச் செயற்பாடுகளில் எவ்வாறு utterances பயன்படுத்தப்படுகின்றன (literally, figuratively, அல்லது வேறுவிதமாக) என்பது பற்றிய ஆய்வு;\nதொடரியல் (syntax) ஒலி, உருபன்,\nஇந்த ஒவ்வொரு பகுதியினதும் தனிப்பட்ட முக்கியத்துவம் எல்லோராலும் ஏற்றுக்கொள்ளப்படுவதில்லை, எனினும், கிட்டத்தட்ட எல்லா மொழியியலாளருமே இந்தப் பிரிவுகள் குறிப்பிடத்தக்க அளவு பொதுப் பகுதிகளைக் கொண்டிருக்கின்றன என்பதை ஒத்துக்கொள்வர். இருந்தாலும் ஒவ்வொரு துணைப்பிரிவும், குறிப்பிடத்தக்க அறிவுபூர்வ ஆய்வுகளைச் செய்யக்கூடிய அளவுக்குத் தனியான அடிப்படையான எண்ணக்கருக்களைக் கொண்டுள்ளன.\"\"\")\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T19:06:58.734440Z","iopub.execute_input":"2024-03-23T19:06:58.734872Z","iopub.status.idle":"2024-03-23T19:07:24.178363Z","shell.execute_reply.started":"2024-03-23T19:06:58.734837Z","shell.execute_reply":"2024-03-23T19:07:24.177200Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"கோட்பாட்டு மொழியியல் பொதுவாக, ஓரளவுக்குத் தனித்தனியாக ஆராயத்தக்க வகையில் பல்வேறு பிரிவுகளாக வகுக்கப்படுகிறது. கீழ்வரும் பிரிவுகள் இன்று பரவலாக ஏற்றுக்கொள்ளப்படுகின்றன: ஒலிப்பியல் (phonetics), ஒரு மொழியில் பயன்படுத்தப்படும் வெவ்வேறு ஒலிகள் பற்றிய துறை; ஒலியியல் (phonology), ஒரு மொழியின் அடிப்படை ஒலிகளின் வடிவத்தை பற்றி ஆராயும் துறை; உருபனியல், சொற்களின் உள் அமைப்பு\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_datasets[\"test\"][\"Summary\"][13]","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:40:08.318496Z","iopub.execute_input":"2024-03-23T18:40:08.318808Z","iopub.status.idle":"2024-03-23T18:40:08.446688Z","shell.execute_reply.started":"2024-03-23T18:40:08.318781Z","shell.execute_reply":"2024-03-23T18:40:08.445665Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'போதை மருந்து வர்த்தகத்தில் ஈடுபட்டதாக கைதாகி சிறையில் இருந்த பிலிப்பைன்ஸ் மேயர் ஒருவர், அவருடைய சிறை அறையிலேயே சுட்டுக் கொல்லப்பட்டுள்ளார்.'"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets[\"test\"][\"Text\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:35:18.051799Z","iopub.execute_input":"2024-03-23T18:35:18.052564Z","iopub.status.idle":"2024-03-23T18:35:18.312795Z","shell.execute_reply.started":"2024-03-23T18:35:18.052531Z","shell.execute_reply":"2024-03-23T18:35:18.311434Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'இது குறித்து அவர் பிபிசி தமிழிடம் கூறுகையில், \"இத்தீர்ப்பை மிகச் சிறந்த முற்போக்கான தீர்ப்பாக பார்க்கிறேன். அடிப்படை உரிமை என்ன என்பதை மிகவும் தீவிரமாக இத்தீர்ப்பு விளக்கியுள்ளது\" என்றார். \"இந்திய அரசியலமைப்பின் 21-ஆவது விதியை மிகவும் ஆழமாக நீதிமன்றம் விளக்கியுள்ளது என்றும், ஏற்கனவே இரு வேறு வழக்குகளில் தனி நபர் அந்தரங்கத்தை அடிப்படை உரிமை பாதுகாக்காது எனக் குறிப்பிட்ட தீர்ப்புகளைத் திருத்தி அந்த உரிமையை தற்போது உச்ச நீதிமன்றம் பாதுகாத்துள்ளது\" என்று என்.ராம் கூறினார். \"ஆதார் பதிவு விவகாரத்தில் இந்த தீர்ப்பு நிச்சயமாக பிரதிபலிக்கும் என்று கூறும் அவர், ஆதார் முறையைத் திணிக்க முயற்சிக்கும் மத்திய அரசின் எண்ணம் இனி கடினமாக இருக்கும்\" என்றார். \"நெருக்கடி காலத்தில் நீதிபதி எச்.ஆர். கன்னா அளித்த தீர்ப்பு ஏற்படுத்திய மாற்றத்தைப் போல இந்தத் தீர்ப்பும் சமூகத்தில் மாற்றத்தை ஏற்படுத்தலாம் என்று சிலர் கருதுவதாகவும், மொத்தத்தில் இது ஒரு முக்கியத்துவம் நிறைந்த தீர்ப்பாகும்\" என்றும் என்.ராம் தெரிவித்தார். பிற செய்திகள் : சமூக ஊடகங்களில் பிபிசி தமிழ் :'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"model_tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:41:10.432494Z","iopub.execute_input":"2024-03-23T18:41:10.433191Z","iopub.status.idle":"2024-03-23T18:41:10.684776Z","shell.execute_reply.started":"2024-03-23T18:41:10.433158Z","shell.execute_reply":"2024-03-23T18:41:10.683823Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"('model_tokenizer/tokenizer_config.json',\n 'model_tokenizer/special_tokens_map.json',\n 'model_tokenizer/vocab.json',\n 'model_tokenizer/sentencepiece.bpe.model',\n 'model_tokenizer/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}